{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Load Video:\n",
    "\n",
    "Load the provided video file."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import cv2\n",
    "\n",
    "video_path = 'scenecutsample.mp4'\n",
    "\n",
    "video_capture = cv2.VideoCapture(video_path)\n",
    "\n",
    "video_loaded = video_capture.isOpened()\n",
    "\n",
    "video_loaded\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Frame Extraction:\n",
    "\n",
    "Extract individual frames from the video."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "638"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "extracted_frames = []\n",
    "\n",
    "frame_index = 0\n",
    "while video_capture.isOpened():\n",
    "    ret, frame = video_capture.read()\n",
    "    \n",
    "    if ret:\n",
    "        extracted_frames.append((frame_index, frame))\n",
    "        frame_index += 1\n",
    "    else:\n",
    "        break\n",
    "\n",
    "video_capture.release()\n",
    "\n",
    "len(extracted_frames)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Spatio-Temporal Segmentation:\n",
    "\n",
    "Perform segmentation on each frame using a technique like color thresholding or edge detection.\\\n",
    "Track the segmented objects across frames to observe changes in motion and shape.\\\n",
    "Identify the regions that remain consistent over time (foreground vs. background segmentation)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "import numpy as np\n",
    "\n",
    "video_path = 'scenecutsample.mp4'\n",
    "video_capture = cv2.VideoCapture(video_path)\n",
    "\n",
    "frame_width = int(video_capture.get(cv2.CAP_PROP_FRAME_WIDTH))\n",
    "frame_height = int(video_capture.get(cv2.CAP_PROP_FRAME_HEIGHT))\n",
    "fps = int(video_capture.get(cv2.CAP_PROP_FPS))\n",
    "\n",
    "fourcc = cv2.VideoWriter_fourcc(*'mp4v')\n",
    "out_fg_mask = cv2.VideoWriter('foreground_mask_output.mp4', fourcc, fps, (frame_width, frame_height), isColor=False)\n",
    "out_edges = cv2.VideoWriter('edges_output.mp4', fourcc, fps, (frame_width, frame_height), isColor=False)\n",
    "\n",
    "ret, first_frame = video_capture.read()\n",
    "gray_first_frame = cv2.cvtColor(first_frame, cv2.COLOR_BGR2GRAY)\n",
    "gray_first_frame = cv2.GaussianBlur(gray_first_frame, (5, 5), 0)\n",
    "\n",
    "while video_capture.isOpened():\n",
    "    ret, frame = video_capture.read()\n",
    "    if not ret:\n",
    "        break\n",
    "    gray_frame = cv2.cvtColor(frame, cv2.COLOR_BGR2GRAY)\n",
    "    gray_frame = cv2.GaussianBlur(gray_frame, (5, 5), 0)\n",
    "    frame_diff = cv2.absdiff(gray_first_frame, gray_frame)\n",
    "    _, fg_mask = cv2.threshold(frame_diff, 25, 255, cv2.THRESH_BINARY)\n",
    "    edges = cv2.Canny(fg_mask, 50, 150)\n",
    "\n",
    "    kernel = np.ones((5, 5), np.uint8)\n",
    "    fg_mask = cv2.morphologyEx(fg_mask, cv2.MORPH_CLOSE, kernel)\n",
    "\n",
    "    out_fg_mask.write(fg_mask)\n",
    "    out_edges.write(edges)\n",
    "\n",
    "    cv2.imshow('Original Frame', frame)\n",
    "    cv2.imshow('Foreground Mask', fg_mask)\n",
    "    cv2.imshow('Edges', edges)\n",
    "\n",
    "    if cv2.waitKey(30) & 0xFF == ord('q'):\n",
    "        break\n",
    "\n",
    "video_capture.release()\n",
    "out_fg_mask.release()\n",
    "out_edges.release()\n",
    "cv2.destroyAllWindows()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Frames saved in the folder: output_frame\n"
     ]
    }
   ],
   "source": [
    "from skimage.metrics import structural_similarity as ssim\n",
    "video_path = 'scenecutsample.mp4'\n",
    "sample_image_path = 'targetimage.jpg' \n",
    "output_dir = 'output_frame'\n",
    "\n",
    "if not os.path.exists(output_dir):\n",
    "    os.makedirs(output_dir)\n",
    "\n",
    "sample_image = cv2.imread(sample_image_path)\n",
    "gray_sample_image = cv2.cvtColor(sample_image, cv2.COLOR_BGR2GRAY)\n",
    "\n",
    "gray_sample_image = cv2.resize(gray_sample_image, (gray_sample_image.shape[1] // 2, gray_sample_image.shape[0] // 2))\n",
    "sample_image_height, sample_image_width = gray_sample_image.shape\n",
    "\n",
    "frame_counter = 0\n",
    "while video_capture.isOpened():\n",
    "    ret, color_frame = video_capture.read() \n",
    "    if not ret:\n",
    "        break\n",
    "    color_frame = cv2.resize(color_frame, (color_frame.shape[1] // 2, color_frame.shape[0] // 2))\n",
    "\n",
    "    gray_frame = cv2.cvtColor(color_frame, cv2.COLOR_BGR2GRAY)\n",
    "\n",
    "    best_ssim = -1\n",
    "    best_x, best_y = 0, 0\n",
    "    step_size = 30\n",
    "\n",
    "    for y in range(0, gray_frame.shape[0] - sample_image_height, step_size):  \n",
    "        for x in range(0, gray_frame.shape[1] - sample_image_width, step_size):\n",
    "            frame_region = gray_frame[y:y + sample_image_height, x:x + sample_image_width]\n",
    "\n",
    "            similarity = ssim(frame_region, gray_sample_image)\n",
    "            if similarity > best_ssim:\n",
    "                best_ssim = similarity\n",
    "                best_x, best_y = x, y\n",
    "\n",
    "    cv2.rectangle(color_frame, (best_x, best_y), (best_x + sample_image_width, best_y + sample_image_height), (0, 255, 0), 2)\n",
    "    output_frame_path = os.path.join(output_dir, f'frame_{frame_counter:04d}.jpg')\n",
    "    cv2.imwrite(output_frame_path, color_frame, [int(cv2.IMWRITE_JPEG_QUALITY), 80])  \n",
    "    \n",
    "    frame_counter += 1\n",
    "\n",
    "video_capture.release()\n",
    "print(f\"Frames saved in the folder: {output_dir}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Scene Cut Detection:\n",
    "\n",
    "Use pixel-based comparison or histogram differences between consecutive frames to detect abrupt changes (hard cuts).\\\n",
    "Detect gradual scene transitions (Soft cuts) by analyzing frame-to-frame intensity changes over time."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def detect_hard_cuts(frames, threshold=500000):\n",
    "    cuts = []\n",
    "    for i in range(1, len(frames)):\n",
    "        diff = cv2.absdiff(frames[i], frames[i-1])\n",
    "        non_zero_count = np.count_nonzero(diff)\n",
    "        if non_zero_count > threshold:\n",
    "            cuts.append(i)\n",
    "    return cuts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "def detect_soft_cuts(frames, hard_cuts, threshold=0.998):\n",
    "    cuts = []\n",
    "    for i in range(1, len(frames)):\n",
    "        if i in hard_cuts:\n",
    "            continue\n",
    "        hist1 = cv2.calcHist([frames[i-1]], [0], None, [256], [0, 256])\n",
    "        hist2 = cv2.calcHist([frames[i]], [0], None, [256], [0, 256])\n",
    "        hist_diff = cv2.compareHist(hist1, hist2, cv2.HISTCMP_CORREL)\n",
    "        if hist_diff < threshold:\n",
    "            cuts.append(i)\n",
    "    return cuts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "def mark_cuts(frames, hard_cuts, soft_cuts):\n",
    "    marked_frames = []\n",
    "    for i, frame in enumerate(frames):\n",
    "        if i in hard_cuts:\n",
    "            cv2.putText(frame, \"Hard Cut\", (50, 50), cv2.FONT_HERSHEY_SIMPLEX, 1, (0, 0, 255), 2, cv2.LINE_AA)\n",
    "            frame = cv2.rectangle(frame, (0, 0), (frame.shape[1], frame.shape[0]), (0, 0, 255), 5)\n",
    "        elif i in soft_cuts:\n",
    "            cv2.putText(frame, \"Soft Cut\", (50, 50), cv2.FONT_HERSHEY_SIMPLEX, 1, (0, 255, 0), 2, cv2.LINE_AA)\n",
    "            frame = cv2.rectangle(frame, (0, 0), (frame.shape[1], frame.shape[0]), (0, 255, 0), 5)\n",
    "        marked_frames.append(frame)\n",
    "    return marked_frames\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Mark Scene Cuts:\n",
    "\n",
    "Highlight the frames where scene cuts are detected.\n",
    "Create a summary displaying the detected scene boundaries."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "segmented_frames_folder = 'segmented_frames'\n",
    "marked_frames_folder = 'marked_frames'\n",
    "if not os.path.exists(marked_frames_folder):\n",
    "    os.makedirs(marked_frames_folder)\n",
    "\n",
    "frame_files = sorted([f for f in os.listdir(segmented_frames_folder) if f.endswith('.png')])\n",
    "\n",
    "frames = []\n",
    "for frame_file in frame_files:\n",
    "    frame_path = os.path.join(segmented_frames_folder, frame_file)\n",
    "    frame = cv2.imread(frame_path)\n",
    "    if frame is None:\n",
    "        print(f\"Error reading frame {frame_file}\")\n",
    "        continue\n",
    "    frames.append(frame)\n",
    "\n",
    "hard_cuts = detect_hard_cuts(frames)\n",
    "soft_cuts = detect_soft_cuts(frames, hard_cuts)\n",
    "marked_frames = mark_cuts(frames, hard_cuts, soft_cuts)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Hard cuts detected at: [30, 48, 95, 429]\n",
      "Soft cuts detected at: [66, 95, 302]\n"
     ]
    }
   ],
   "source": [
    "for i, marked_frame in enumerate(marked_frames):\n",
    "    frame_filename = os.path.join(marked_frames_folder, f'marked_frame_{i:04d}.png')\n",
    "    cv2.imwrite(frame_filename, marked_frame)\n",
    "\n",
    "print(f\"Hard cuts detected at: {hard_cuts}\")\n",
    "print(f\"Soft cuts detected at: {soft_cuts}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Result Visualization:\n",
    "\n",
    "Display frames where scene cuts are identified and show segmentation results for selected frames."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "import os\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "segmented_frames_folder = 'segmented_frames'\n",
    "frame_files = sorted([f for f in os.listdir(segmented_frames_folder) if f.endswith('.png')])\n",
    "\n",
    "cut_indices = set(hard_cuts + soft_cuts)  \n",
    "for i in cut_indices:\n",
    "    if i < len(frame_files):\n",
    "        frame_path = os.path.join(segmented_frames_folder, frame_files[i])\n",
    "        frame = cv2.imread(frame_path)\n",
    "        if frame is None:\n",
    "            print(f\"Error reading frame {frame_files[i]}\")\n",
    "            continue\n",
    "        \n",
    "        frame_rgb = cv2.cvtColor(frame, cv2.COLOR_BGR2RGB)\n",
    "        \n",
    "        plt.figure(figsize=(10, 6))\n",
    "        plt.imshow(frame_rgb)\n",
    "        if i in hard_cuts and i in soft_cuts:\n",
    "            plt.title(f\"Hard and Soft Cut at Frame {i}\")\n",
    "        elif i in hard_cuts:\n",
    "            plt.title(f\"Hard Cut at Frame {i}\")\n",
    "        elif i in soft_cuts:\n",
    "            plt.title(f\"Soft Cut at Frame {i}\")\n",
    "        \n",
    "        plt.axis('off') \n",
    "        plt.show()\n",
    "    else:\n",
    "        print(f\"Frame index {i} is out of bounds for the available frames.\")\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
